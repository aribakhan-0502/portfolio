{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4801b291",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1>Project Portfolio # 1</h1>\n",
    "    <h2>Part 2: OLTP > Data Mart Pipeline</h2>\n",
    "    <h3>Coded by: Ariba Khan</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b85111a",
   "metadata": {},
   "source": [
    "A data mart will be created to record important metrics and analytics focusing on the following areas:\n",
    "\n",
    "- Delay Analysis\n",
    "- Revenue Analysis\n",
    "- Incidents Analysis\n",
    "\n",
    "#### Grain\n",
    "\n",
    "One row of the fact table will represent one trip.\n",
    "\n",
    "#### Dimension Tables\n",
    "\n",
    "The following list consists of our dimension table entities, and the table following it breaks down their attributes:\n",
    "\n",
    "- DimDate\n",
    "- DimRoutes\n",
    "- DimIncidents\n",
    "- DimComplaints\n",
    "- DimBuses\n",
    "- DimPayments\n",
    "\n",
    "#### Fact Table\n",
    "\n",
    "The fact table snapshot will combine all columns of the dimension tables and will have the following facts as key columns:\n",
    "\n",
    "- Scheduled_Departure\n",
    "- Scheduled_Arrival\n",
    "- Actual_Departure\n",
    "- Actual_Arrival\n",
    "- Delay_Departure\n",
    "- Delay_Arrival\n",
    "- IncidentCount\n",
    "- ComplaintCount\n",
    "- TotalFare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea7ea9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h3>Importing All Needed Libraries</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d3d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bb7d96",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h3>Connecting OLTP and Data Mart</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988cb41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLTP connection\n",
    "oltp_engine = create_engine('postgresql://aribaandsumbal:DAWproject@localhost:5432/Public Transport (Karachi)')\n",
    "\n",
    "# Data Mart connection\n",
    "dw_engine = create_engine('postgresql://aribaandsumbal:DAWproject@localhost:5432/Public Transport - Data Mart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d47eb6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h3>Data Ingestion</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ea00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table(table_name, engine):\n",
    "    query = f'SELECT * FROM \"{table_name}\";'\n",
    "    return pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90be713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['Buses', 'Routes', 'Fares', 'Tickets', 'Payments', 'Incidents', 'Complaints', 'Trips']\n",
    "\n",
    "staging_data = {table: extract_table(table, oltp_engine) for table in tables}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24065b35",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h3>Staging Area</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564284de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treating missing values\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    if df.isnull().any().any():\n",
    "        df = df.interpolate()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb432de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table, df in staging_data.items():\n",
    "    staging_data[table] = handle_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67eeb50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing all tables in separate dataframes\n",
    "\n",
    "buses_df = staging_data['Buses']\n",
    "routes_df = staging_data['Routes']\n",
    "fares_df = staging_data['Fares']\n",
    "tickets_df = staging_data['Tickets']\n",
    "payments_df = staging_data['Payments']\n",
    "incidents_df = staging_data['Incidents']\n",
    "complaints_df = staging_data['Complaints']\n",
    "trips_df = staging_data['Trips']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12599643",
   "metadata": {},
   "source": [
    "#### Creating Dimension Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c96fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DimDate\n",
    "\n",
    "start_date = datetime(2023, 6, 1)\n",
    "end_date = datetime(2024, 5, 31)\n",
    "date_range = pd.date_range(start_date, end_date)\n",
    "\n",
    "# creating DimDate dataframe\n",
    "dim_date = pd.DataFrame({\n",
    "    'DateID': date_range,\n",
    "    'Day': date_range.day,\n",
    "    'Week': date_range.isocalendar().week,\n",
    "    'Month': date_range.month,\n",
    "    'Quarter': date_range.quarter,\n",
    "    'Year': date_range.year,\n",
    "    'DayOfWeek': date_range.dayofweek + 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb232790",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DimBuses\n",
    "\n",
    "dim_buses = buses_df.copy()\n",
    "dim_buses.rename(columns={'bus_id': 'BusID', 'bus_name': 'BusName', 'bus_type': 'BusType', 'capacity': 'Cap'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0909e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DimRoutes\n",
    "\n",
    "dim_routes = routes_df.copy()\n",
    "dim_routes.rename(columns={\n",
    "    'route_id': 'RouteID', 'route_name': 'RouteName', 'route_origin': 'RouteOrigin', \n",
    "    'route_dest': 'RouteDestination', 'origin_lat': 'OriginLat', 'origin_long': 'OriginLong', \n",
    "    'dest_lat': 'DestLat', 'dest_long': 'DestLong'}, inplace=True)\n",
    "dim_routes = dim_routes.drop(columns = 'bus_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ee1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DimIncidents\n",
    "\n",
    "dim_incidents = incidents_df[['incident_id', 'incident_type', 'incident_time', 'trip_id']].copy()\n",
    "dim_incidents = dim_incidents.drop_duplicates(subset='trip_id')\n",
    "dim_incidents['incident_id'] = [f'INC{str(i).zfill(3)}' for i in range(1, len(dim_incidents) + 1)]\n",
    "dim_incidents.rename(columns={'incident_id': 'IncidentID', 'incident_type': 'IncType', 'incident_time': 'Time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d140fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DimTickets\n",
    "\n",
    "# joining relevant tables together\n",
    "tickets_payments = tickets_df.merge(payments_df, on='payment_id')\n",
    "tickets_payments_fares = tickets_payments.merge(fares_df, on='fare_id')\n",
    "\n",
    "# aggregating data\n",
    "dim_tickets = tickets_payments_fares.groupby('trip_id').agg(\n",
    "    TotalTickets=('ticket_id', 'count'),\n",
    "    CashCount=('payment_method', lambda x: (x == 'Cash').sum()),\n",
    "    CreditCount=('payment_method', lambda x: (x == 'Credit Card').sum()),\n",
    "    DebitCount=('payment_method', lambda x: (x == 'Debit Card').sum()),\n",
    "    WalletCount=('payment_method', lambda x: (x == 'Digital Wallet').sum()),\n",
    "    TypeStudent=('fare_type', lambda x: (x == 'Student').sum()),\n",
    "    TypeRegular=('fare_type', lambda x: (x == 'Regular').sum())\n",
    ").reset_index()\n",
    "\n",
    "# fixing primary key\n",
    "dim_tickets.rename(columns={'trip_id': 'TicketID'}, inplace=True)\n",
    "dim_tickets['TicketID'] = [f'TCK{str(i).zfill(3)}' for i in range(1, len(dim_tickets) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf38807",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DimComplaints\n",
    "\n",
    "# aggregating data\n",
    "dim_complaints = complaints_df.groupby('trip_id').agg(\n",
    "    CountDelay=('comp_type', lambda x: (x == 'Delay').sum()),\n",
    "    CountCleanliness=('comp_type', lambda x: (x == 'Cleanliness').sum()),\n",
    "    CountRudeStaff=('comp_type', lambda x: (x == 'Rude Staff').sum()),\n",
    "    CountOvercrowding=('comp_type', lambda x: (x == 'Overcrowding').sum()),\n",
    "    CountNoise=('comp_type', lambda x: (x == 'Noisy Environment').sum()),\n",
    "    CountSeats=('comp_type', lambda x: (x == 'Uncomfortable Seats').sum()),\n",
    "    CountRouteChange=('comp_type', lambda x: (x == 'Route Change').sum()),\n",
    "    CountAirCon=('comp_type', lambda x: (x == 'Poor Air Conditioning').sum()),\n",
    "    CountSafety=('comp_type', lambda x: (x == 'Safety Concerns').sum()),\n",
    "    CountAccessibility=('comp_type', lambda x: (x == 'Accessibility Issues').sum())\n",
    ").reset_index()\n",
    "\n",
    "dim_complaints['ComplaintID'] = [f'CMP{str(i).zfill(3)}' for i in range(1, len(dim_complaints) + 1)]\n",
    "\n",
    "complaints_order = ['ComplaintID', 'CountDelay', 'CountCleanliness', 'CountRudeStaff', 'CountOvercrowding', 'CountNoise', \n",
    "                    'CountSeats', 'CountRouteChange', 'CountAirCon', 'CountSafety', 'CountAccessibility', 'trip_id']\n",
    "dim_complaints = dim_complaints[complaints_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c3052e",
   "metadata": {},
   "source": [
    "#### Creating Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c1e5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_trip_performance = trips_df.copy()\n",
    "\n",
    "# calculating delays\n",
    "fact_trip_performance['Delay_Departure'] = abs((pd.to_datetime(fact_trip_performance['actual_departure_time']) - pd.to_datetime(fact_trip_performance['departure_time'])).dt.total_seconds() / 60)\n",
    "fact_trip_performance['Delay_Arrival'] = abs((pd.to_datetime(fact_trip_performance['actual_arrival_time']) - pd.to_datetime(fact_trip_performance['arrival_time'])).dt.total_seconds() / 60)\n",
    "\n",
    "# creating incident and complaint counts\n",
    "incident_counts = incidents_df.groupby('trip_id').size().reset_index(name='IncidentCount')\n",
    "complaint_counts = complaints_df.groupby('trip_id').size().reset_index(name='ComplaintCount')\n",
    "fact_trip_performance = fact_trip_performance.merge(incident_counts, how='left', left_on='trip_id', right_on='trip_id').fillna({'IncidentCount': 0})\n",
    "fact_trip_performance = fact_trip_performance.merge(complaint_counts, how='left', left_on='trip_id', right_on='trip_id').fillna({'ComplaintCount': 0})\n",
    "\n",
    "# calculating total fare\n",
    "total_fare = tickets_payments_fares.groupby('trip_id')['payment_amount'].sum().reset_index(name='TotalFare')\n",
    "fact_trip_performance = fact_trip_performance.merge(total_fare, how='left', on='trip_id')\n",
    "\n",
    "# adding 'TicketID'\n",
    "fact_trip_performance['TicketID'] = dim_tickets['TicketID']\n",
    "\n",
    "# renaming columns\n",
    "fact_trip_performance = fact_trip_performance.rename(columns={\n",
    "    'trip_id': 'TripID', 'route_id': 'RouteID', 'bus_id': 'BusID', 'trip_date': 'DateID', 'departure_time': 'Scheduled_Departure', \n",
    "    'arrival_time': 'Scheduled_Arrival', 'actual_departure_time': 'Actual_Departure', 'actual_arrival_time': 'Actual_Arrival'\n",
    "})\n",
    "\n",
    "# adding 'IncidentID'\n",
    "fact_trip_performance = fact_trip_performance.merge(dim_incidents[['IncidentID', 'trip_id']], \n",
    "                                                    how='left', left_on='TripID', right_on='trip_id')\n",
    "fact_trip_performance = fact_trip_performance.drop(columns=['trip_id'])\n",
    "dim_incidents = dim_incidents.drop(columns=['trip_id'])\n",
    "\n",
    "# adding 'ComplaintID'\n",
    "fact_trip_performance = fact_trip_performance.merge(dim_complaints[['ComplaintID', 'trip_id']], \n",
    "                                                    how='left', left_on='TripID', right_on='trip_id')\n",
    "fact_trip_performance = fact_trip_performance.drop(columns=['trip_id'])\n",
    "dim_complaints = dim_complaints.drop(columns=['trip_id'])\n",
    "\n",
    "# dropping irrelevant columns\n",
    "fact_trip_performance = fact_trip_performance.drop(columns = ['cond_id', 'driver_id', 'sched_id'])\n",
    "\n",
    "# fixing order of columns\n",
    "fact_order = ['TripID', 'DateID', 'RouteID', 'BusID', 'TicketID', 'ComplaintID', 'IncidentID', 'Scheduled_Departure',\n",
    "              'Scheduled_Arrival', 'Actual_Departure', 'Actual_Arrival', 'Delay_Departure', 'Delay_Arrival', 'IncidentCount',\n",
    "              'ComplaintCount', 'TotalFare']\n",
    "fact_trip_performance = fact_trip_performance[fact_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93968664",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h3>Loading Data Onto Data Mart</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e732f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_dw(df, table_name, engine):\n",
    "    df.to_sql(table_name, engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98699356",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_dw(dim_date, 'DimDate', dw_engine)\n",
    "load_to_dw(dim_buses, 'DimBuses', dw_engine)\n",
    "load_to_dw(dim_routes, 'DimRoutes', dw_engine)\n",
    "load_to_dw(dim_incidents, 'DimIncidents', dw_engine)\n",
    "load_to_dw(dim_tickets, 'DimTickets', dw_engine)\n",
    "load_to_dw(dim_complaints, 'DimComplaints', dw_engine)\n",
    "load_to_dw(fact_trip_performance, 'FactTripPerformance', dw_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab24c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h3>Generating Fact Table SnapShot</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd3f7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot = pd.merge(fact_trip_performance, dim_date, on='DateID', how='left')\n",
    "snapshot = pd.merge(snapshot, dim_routes, on='RouteID', how='left')\n",
    "snapshot = pd.merge(snapshot, dim_buses, on='BusID', how='left')\n",
    "snapshot = pd.merge(snapshot, dim_tickets, on='TicketID', how='left')\n",
    "snapshot = pd.merge(snapshot, dim_complaints, on='ComplaintID', how='left')\n",
    "snapshot = pd.merge(snapshot, dim_incidents, on='IncidentID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3748ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_to_dw(snapshot, 'FactTableSnapshot', dw_engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
